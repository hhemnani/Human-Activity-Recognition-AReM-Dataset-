{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Hemnani_Hitika_HW3</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Hitika Hemnani\n",
    "<br>\n",
    "Github Username: hhemnani\n",
    "<br>\n",
    "USC ID: 8304678802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARem_data = \"../data/AReM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###I manually Splitted Train and Test Data but it was difficult to access them during feature extraction so I am Appending Traing and Test data into list of directory/files\n",
    "##So I can access them easily later on\n",
    "\n",
    "\n",
    "training_data = []\n",
    "testing_data = []\n",
    "\n",
    "## looping through all the directories in the AReM Dataset\n",
    "for activity in os.listdir(ARem_data):\n",
    "    activity_path = os.path.join(ARem_data, activity)\n",
    "    \n",
    "    # For the images -->skip\n",
    "    if not os.path.isdir(activity_path):\n",
    "        continue\n",
    "        \n",
    "    # again looping through all the dataset files this time\n",
    "    for file in os.listdir(activity_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(activity_path, file)\n",
    "            \n",
    "            ##Extracting File Numbers to split\n",
    "            dataset_number = int(file.replace('dataset', '').replace('.csv', ''))\n",
    "\n",
    "            ##Splitting the data\n",
    "            if activity in ['bending1', 'bending2']:\n",
    "                if dataset_number <= 2:\n",
    "                    testing_data.append((file_path, activity))\n",
    "                else:\n",
    "                    training_data.append((file_path, activity))\n",
    "            else:\n",
    "                if dataset_number <= 3:\n",
    "                    testing_data.append((file_path, activity))\n",
    "                else:\n",
    "                    training_data.append((file_path, activity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data\n",
    "##testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "ref:https://www.researchgate.net/figure/List-of-extracted-time-domain-features-from-each-window-size_tbl2_327523090\n",
    "\n",
    "\n",
    "##### Common Time-Domain Features for Time Series Classification:\n",
    "Minimum:\n",
    "The smallest value in the time series. It helps capture the lower bound of the data range.\n",
    "\n",
    "Maximum:\n",
    "The largest value in the time series. It helps capture the upper bound of the data range.\n",
    "\n",
    "Mean:\n",
    "The average value of the time series. It provides information about the central tendency of the data.\n",
    "\n",
    "Median:\n",
    "The middle value when the time series data is sorted. The median is less sensitive to outliers than the mean.\n",
    "\n",
    "Standard Deviation (STD):\n",
    "A measure of the spread or dispersion of the values in the time series. It indicates how much variation or \"noise\" is present.\n",
    "\n",
    "Variance:\n",
    "The square of the standard deviation. It measures the degree of variation in the time series data.\n",
    "\n",
    "Range:\n",
    "The difference between the maximum and minimum values. It is another measure of data dispersion.\n",
    "\n",
    "Root Mean Square (RMS):\n",
    "The square root of the mean of the squared values. This can give insights into the overall energy of the signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature Extraction function to extract time-domain features\n",
    "\n",
    "def extracting_time_features(time_data):\n",
    "    # minimum=np.min(time_data)\n",
    "    # maximum=np.max(time_data)\n",
    "    # mean=np.mean(time_data)\n",
    "    # median=np.median(time_data)\n",
    "    # STD=np.std(time_data)\n",
    "    # Q1 = np.percentile(time_data, 25)\n",
    "    # Q3 = np.percentile(time_data, 75)\n",
    "\n",
    "    # return [minimum,maximum,mean,median,STD,Q1,Q3]\n",
    "    ##this idea is not used much simpler to just add values directly to columns\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    ###Here I was considering all the columns I was getting the wrong output as the time column was also considered \n",
    "    ##Hence skipping 1st column\n",
    "    for i, column in enumerate(time_data.columns[1:], start=1):\n",
    "        \n",
    "        ##Error Handeling->type error occured\n",
    "        series = pd.to_numeric(time_data[column], errors='coerce')\n",
    "        series = series.dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        \n",
    "        features.update({\n",
    "            f'min{i}': np.min(series),\n",
    "            f'max{i}': np.max(series),\n",
    "            f'mean{i}': np.mean(series),\n",
    "            f'median{i}': np.median(series),\n",
    "            f'std{i}': np.std(series),\n",
    "            f'1st_quart{i}': np.percentile(series, 25),\n",
    "            f'3rd_quart{i}': np.percentile(series, 75)\n",
    "        })\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=[]\n",
    "testing_df=[]\n",
    "\n",
    "##looping to get all the datasets\n",
    "for path, activity in training_data:\n",
    "    time_data=pd.read_csv(path, sep=',', skiprows=4, on_bad_lines='skip')\n",
    "    # print(time_data)\n",
    "    features = extracting_time_features(time_data)\n",
    "    features['activity'] = activity\n",
    "    training_df.append(features)\n",
    "\n",
    "##Same for testing data\n",
    "for path, activity in testing_data:\n",
    "    time_data = pd.read_csv(path, sep=',', skiprows=4, on_bad_lines='skip')\n",
    "    features = extracting_time_features(time_data)\n",
    "    features['activity'] = activity\n",
    "    testing_df.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to DataFrames\n",
    "training_df = pd.DataFrame(training_df)\n",
    "testing_df = pd.DataFrame(testing_df)\n",
    "new_dataset = pd.concat([training_df, testing_df], ignore_index=True)\n",
    "\n",
    "# Adding 'Instance' column to match the assignment requirements\n",
    "new_dataset.insert(0, 'Instance', range(1, len(new_dataset) + 1))\n",
    "new_dataset.drop(columns=['activity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st_quart1</th>\n",
       "      <th>3rd_quart1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st_quart5</th>\n",
       "      <th>3rd_quart5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st_quart6</th>\n",
       "      <th>3rd_quart6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.330</td>\n",
       "      <td>1.557210</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.997520</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.512971</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179812</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.666840</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.845436</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.241152</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>2.408514</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.454958</td>\n",
       "      <td>43.250</td>\n",
       "      <td>1.384653</td>\n",
       "      <td>42.50</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2.486268</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>24.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.679646</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.621885</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>36.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.969125</td>\n",
       "      <td>44.500</td>\n",
       "      <td>1.616677</td>\n",
       "      <td>43.31</td>\n",
       "      <td>44.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.314843</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>23.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.555312</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.487318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>35.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>43.174938</td>\n",
       "      <td>43.670</td>\n",
       "      <td>1.986979</td>\n",
       "      <td>42.50</td>\n",
       "      <td>44.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.980866</td>\n",
       "      <td>12.7500</td>\n",
       "      <td>16.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.911979</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.665467</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>32.75</td>\n",
       "      <td>47.00</td>\n",
       "      <td>42.760562</td>\n",
       "      <td>44.500</td>\n",
       "      <td>3.395376</td>\n",
       "      <td>41.33</td>\n",
       "      <td>45.3725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>4.292096</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>18.565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.842271</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.721413</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>19.33</td>\n",
       "      <td>43.50</td>\n",
       "      <td>34.227771</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.884480</td>\n",
       "      <td>30.50</td>\n",
       "      <td>37.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.088871</td>\n",
       "      <td>14.7500</td>\n",
       "      <td>18.670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>3.394125</td>\n",
       "      <td>3.100</td>\n",
       "      <td>1.790222</td>\n",
       "      <td>2.105</td>\n",
       "      <td>4.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>12.50</td>\n",
       "      <td>45.00</td>\n",
       "      <td>33.509729</td>\n",
       "      <td>34.125</td>\n",
       "      <td>4.845868</td>\n",
       "      <td>30.50</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.130299</td>\n",
       "      <td>14.6275</td>\n",
       "      <td>18.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.96</td>\n",
       "      <td>3.378479</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1.785497</td>\n",
       "      <td>2.060</td>\n",
       "      <td>4.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>46.75</td>\n",
       "      <td>34.660583</td>\n",
       "      <td>35.000</td>\n",
       "      <td>5.309571</td>\n",
       "      <td>31.00</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>...</td>\n",
       "      <td>3.151727</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.99</td>\n",
       "      <td>3.244396</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.629283</td>\n",
       "      <td>2.120</td>\n",
       "      <td>4.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Instance   min1   max1      mean1  median1      std1  1st_quart1  \\\n",
       "0          1  35.00  47.40  43.954500   44.330  1.557210       43.00   \n",
       "1          2  33.00  47.75  42.179812   43.500  3.666840       39.15   \n",
       "2          3  33.00  45.75  41.678063   41.750  2.241152       41.33   \n",
       "3          4  37.00  48.00  43.454958   43.250  1.384653       42.50   \n",
       "4          5  36.25  48.00  43.969125   44.500  1.616677       43.31   \n",
       "..       ...    ...    ...        ...      ...       ...         ...   \n",
       "83        84  35.50  46.25  43.174938   43.670  1.986979       42.50   \n",
       "84        85  32.75  47.00  42.760562   44.500  3.395376       41.33   \n",
       "85        86  19.33  43.50  34.227771   35.500  4.884480       30.50   \n",
       "86        87  12.50  45.00  33.509729   34.125  4.845868       30.50   \n",
       "87        88  15.00  46.75  34.660583   35.000  5.309571       31.00   \n",
       "\n",
       "    3rd_quart1  min2   max2  ...      std5  1st_quart5  3rd_quart5  min6  \\\n",
       "0      45.0000   0.0   1.70  ...  1.997520     35.3625      36.500   0.0   \n",
       "1      45.0000   0.0   3.00  ...  3.845436     30.4575      36.330   0.0   \n",
       "2      42.7500   0.0   2.83  ...  2.408514     28.4575      31.250   0.0   \n",
       "3      45.0000   0.0   1.58  ...  2.486268     22.2500      24.000   0.0   \n",
       "4      44.6700   0.0   1.50  ...  3.314843     20.5000      23.750   0.0   \n",
       "..         ...   ...    ...  ...       ...         ...         ...   ...   \n",
       "83     44.5000   0.0   2.12  ...  2.980866     12.7500      16.500   0.0   \n",
       "84     45.3725   0.0   3.34  ...  4.292096     13.0000      18.565   0.0   \n",
       "85     37.7500   0.0  14.50  ...  3.088871     14.7500      18.670   0.0   \n",
       "86     36.7500   0.0  13.05  ...  3.130299     14.6275      18.750   0.0   \n",
       "87     38.2500   0.0  13.44  ...  3.151727     14.2500      18.500   0.0   \n",
       "\n",
       "    max6     mean6  median6      std6  1st_quart6  3rd_quart6  \n",
       "0   1.79  0.493292    0.430  0.512971       0.000       0.940  \n",
       "1   2.18  0.613521    0.500  0.523771       0.000       1.000  \n",
       "2   1.79  0.383292    0.430  0.388759       0.000       0.500  \n",
       "3   5.26  0.679646    0.500  0.621885       0.430       0.870  \n",
       "4   2.96  0.555312    0.490  0.487318       0.000       0.830  \n",
       "..   ...       ...      ...       ...         ...         ...  \n",
       "83  5.72  0.911979    0.830  0.665467       0.470       1.220  \n",
       "84  5.73  0.842271    0.710  0.721413       0.430       1.090  \n",
       "85  9.74  3.394125    3.100  1.790222       2.105       4.425  \n",
       "86  8.96  3.378479    3.085  1.785497       2.060       4.440  \n",
       "87  8.99  3.244396    3.000  1.629283       2.120       4.240  \n",
       "\n",
       "[88 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_TDF = [col for col in new_dataset.columns if col not in ['Instance']]\n",
    "\n",
    "##Bootstraping\n",
    "bootstrap_no = 1000 \n",
    "confidence_level = 0.90 \n",
    "results_for_every_feature = {}\n",
    "\n",
    "for feature in only_TDF:\n",
    "    feature_data = new_dataset[feature]\n",
    "    all_std = []\n",
    "    for i in range(bootstrap_no):\n",
    "        sampling = feature_data.sample(n=len(feature_data), replace=True)\n",
    "        all_std.append(sampling.std())\n",
    "    \n",
    "    lower_bound= np.percentile(all_std, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(all_std, (1 + confidence_level) / 2 * 100)\n",
    "\n",
    "    results_for_every_feature[feature] = {\n",
    "        'std_dev': feature_data.std(),\n",
    "        '90%_confidence_lower': lower_bound,\n",
    "        '90%_confidence_upper': upper_bound \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_for_every_feature_df=pd.DataFrame(results_for_every_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st_quart1</th>\n",
       "      <th>3rd_quart1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st_quart5</th>\n",
       "      <th>3rd_quart5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st_quart6</th>\n",
       "      <th>3rd_quart6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std_dev</th>\n",
       "      <td>9.624011</td>\n",
       "      <td>4.207745</td>\n",
       "      <td>5.276413</td>\n",
       "      <td>5.386624</td>\n",
       "      <td>1.769467</td>\n",
       "      <td>6.128143</td>\n",
       "      <td>5.031028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.059656</td>\n",
       "      <td>1.577941</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011324</td>\n",
       "      <td>6.122142</td>\n",
       "      <td>5.563553</td>\n",
       "      <td>0.046101</td>\n",
       "      <td>2.533515</td>\n",
       "      <td>1.157299</td>\n",
       "      <td>1.089858</td>\n",
       "      <td>0.516463</td>\n",
       "      <td>0.761645</td>\n",
       "      <td>1.527012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%_confidence_lower</th>\n",
       "      <td>8.259495</td>\n",
       "      <td>3.182013</td>\n",
       "      <td>4.625094</td>\n",
       "      <td>4.745278</td>\n",
       "      <td>1.559068</td>\n",
       "      <td>5.533800</td>\n",
       "      <td>4.177165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.619758</td>\n",
       "      <td>1.393645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>4.838210</td>\n",
       "      <td>4.409015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.261097</td>\n",
       "      <td>1.063831</td>\n",
       "      <td>1.005226</td>\n",
       "      <td>0.478211</td>\n",
       "      <td>0.693671</td>\n",
       "      <td>1.408581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%_confidence_upper</th>\n",
       "      <td>10.760537</td>\n",
       "      <td>5.148286</td>\n",
       "      <td>5.834165</td>\n",
       "      <td>5.955424</td>\n",
       "      <td>1.953446</td>\n",
       "      <td>6.620401</td>\n",
       "      <td>5.739224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.414007</td>\n",
       "      <td>1.711567</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217155</td>\n",
       "      <td>7.284673</td>\n",
       "      <td>6.639889</td>\n",
       "      <td>0.078915</td>\n",
       "      <td>2.760399</td>\n",
       "      <td>1.218537</td>\n",
       "      <td>1.151525</td>\n",
       "      <td>0.543329</td>\n",
       "      <td>0.808547</td>\n",
       "      <td>1.599291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           min1      max1     mean1   median1      std1  \\\n",
       "std_dev                9.624011  4.207745  5.276413  5.386624  1.769467   \n",
       "90%_confidence_lower   8.259495  3.182013  4.625094  4.745278  1.559068   \n",
       "90%_confidence_upper  10.760537  5.148286  5.834165  5.955424  1.953446   \n",
       "\n",
       "                      1st_quart1  3rd_quart1  min2      max2     mean2  ...  \\\n",
       "std_dev                 6.128143    5.031028   0.0  5.059656  1.577941  ...   \n",
       "90%_confidence_lower    5.533800    4.177165   0.0  4.619758  1.393645  ...   \n",
       "90%_confidence_upper    6.620401    5.739224   0.0  5.414007  1.711567  ...   \n",
       "\n",
       "                          std5  1st_quart5  3rd_quart5      min6      max6  \\\n",
       "std_dev               1.011324    6.122142    5.563553  0.046101  2.533515   \n",
       "90%_confidence_lower  0.793258    4.838210    4.409015  0.000000  2.261097   \n",
       "90%_confidence_upper  1.217155    7.284673    6.639889  0.078915  2.760399   \n",
       "\n",
       "                         mean6   median6      std6  1st_quart6  3rd_quart6  \n",
       "std_dev               1.157299  1.089858  0.516463    0.761645    1.527012  \n",
       "90%_confidence_lower  1.063831  1.005226  0.478211    0.693671    1.408581  \n",
       "90%_confidence_upper  1.218537  1.151525  0.543329    0.808547    1.599291  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_for_every_feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the time-domain features extracted from the AReM dataset, I selected the following three features as the most important for human activity recognition:\n",
    "\n",
    "Mean: It shows the average value of the data, which can help differentiate activities based on their overall data strength.\n",
    "\n",
    "Standard Deviation: It measures how much the data varies over time, which is useful for telling apart activities with smooth or irregular patterns.\n",
    "\n",
    "Maximum: It tells us the highest value of the data, which can help identify activities with sudden or intense movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic regression model has more parameters and can fit the training data more closely than the linear model, even if the true relationship is linear.\n",
    "\n",
    "Therefore, the training RSS for the cubic regression will generally be lower than the training RSS for the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the true relationship is linear, the linear regression model is the correct model.\n",
    "\n",
    "The cubic regression model, being more flexible, may overfit the training data by capturing noise (random fluctuations) rather than the true underlying relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic regression model is more flexible and can better capture non-linear patterns in the data.\n",
    "\n",
    "Therefore, the training RSS for the cubic regression will generally be lower than the training RSS for the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the true relationship is non-linear, the linear regression model will underfit the data, resulting in poor performance on both training and test data.\n",
    "\n",
    "The cubic regression model, being more flexible, can better capture the true non-linear relationship and generalize well to new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
